# 📚 Chinese Historical Documents Assistant(CHDA)

## 中国历史文献推荐小助手

基于 `DGL（Deep Graph Library）` 框架训练模型，内置了自采数据集、训练过程、评测过程以及一个小应用。

## 快速开始

```python
pip install dgl torch gensim fasttext
```

框架参考：[https://www.dgl.ai/pages/start.html](https://www.dgl.ai/pages/start.html)

## 数据集

目前提供一个简单的历史类文献引用的数据集，并给定了每篇文献一个特定的 `uuid` 以便识别。可按照格式，自行导出自有数据集到 `paper.json`，由于目前下游任务为链接预测，故在训练样本的正样本直接使用了全量的数据集，负样本则自动补齐算出相同的不存在的链接，以供模型训练过程中进行验证与比对。

## 主函数

### 特征处理

在模型训练的特征处理中，目前提取：标题+发表年份+期刊名+作者名+摘要。目前仅提供了一个非常基础的文本特征处理方式（`fasttext`）与热编码(`one-hot`)，在实际应用中，您可能需要使用更高级的文本表示方法，如 `TF-IDF`、`Word2Vec` 或 `BERT` 等。

### 二部图模拟

此外，超边到图的转换过程也需要根据您具体的数据结构和需求来设计。目前直接做了二部图，将超图转为了标准图来做的（这样也解决了引用方向的问题）相当于降维再跑 `GNN` 里的 `GraphConv`。

如：一篇文章引用了若干文献，则这篇文章为单个文章节点，与其引用的文献节点组中，用一个额外的独立节点作为抽象超边进行连接，即一头被这篇文章连接，一头连接这篇文章所引用的文献组。

可表示为：文章（单节点） -> 超边（单节点） -> 文献组（若干节点）

## 训练与验证

```python
python train_dgl.py
```

## 小应用

`WIP`

## Roadmap

- [x] 文本特征的预处理：对于文本类特征（如标题和摘要），通常需要通过自然语言处理技术将其转换为数值型特征向量，常用的方法包括 TF-IDF、Word2Vec、BERT 等。
- [x] 特征工程：对于类别型特征（如作者），可以使用独热编码(one-hot)等技术。此外，还可以设计特定的特征，如基于引用数量的特征，来捕捉节点的影响力等属性。
- [x] 模型设计：设计图神经网络模型时，需要考虑如何有效整合节点特征和图结构信息。这可能涉及选择合适的图卷积层、激活函数、以及正则化技术等。
- [ ] 配套小应用示例
